"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.tokenizeSelector = void 0;
const core_1 = require("@tokey/core");
function tokenizeSelector(source, options = {}) {
    const parseLineComments = false; // why would that be a choice?
    return (0, core_1.tokenize)(source, {
        isDelimiter,
        isStringDelimiter(char, previousChar) {
            return previousChar !== `\\` && (0, core_1.isStringDelimiter)(char);
        },
        isWhitespace: core_1.isWhitespace,
        shouldAddToken: () => true,
        createToken: core_1.createToken,
        getCommentStartType: parseLineComments
            ? core_1.getJSCommentStartType
            : core_1.getMultilineCommentStartType,
        isCommentEnd: core_1.isCommentEnd,
        getUnclosedComment: core_1.getUnclosedComment,
        offset: options.offset,
    });
}
exports.tokenizeSelector = tokenizeSelector;
const isDelimiter = (char, previousChar) => previousChar !== '\\' &&
    (char === '[' ||
        char === ']' ||
        char === '(' ||
        char === ')' ||
        char === ',' ||
        char === '*' ||
        char === '|' ||
        char === ':' ||
        char === '.' ||
        char === '#' ||
        char === '>' ||
        char === '~' ||
        char === '+' ||
        char === '{' ||
        char === '}' ||
        char === '&');
//# sourceMappingURL=tokenizer.js.map