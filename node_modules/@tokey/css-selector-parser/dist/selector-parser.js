"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.parseCssSelector = void 0;
const tokenizer_1 = require("./tokenizer");
const nth_parser_1 = require("./nth-parser");
const helpers_1 = require("./helpers");
const core_1 = require("@tokey/core");
function parseCssSelector(source, options = {}) {
    return parseTokens(source, (0, tokenizer_1.tokenizeSelector)(source, options));
}
exports.parseCssSelector = parseCssSelector;
function parseTokens(source, tokens) {
    return new core_1.Seeker(tokens).run(handleToken, [], source);
}
function handleToken(token, selectors, source, s) {
    let t;
    const currentSelector = (0, helpers_1.ensureSelector)(selectors, token);
    const ast = currentSelector.nodes;
    if (token.type === '.') {
        const comments = s.takeMany('multi-comment').map(helpers_1.createCommentAst);
        const name = s.take('text');
        ast.push({
            type: 'class',
            value: name?.value ?? '',
            start: token.start,
            end: name?.end ?? (0, core_1.last)(comments)?.end ?? token.end,
            dotComments: comments,
        });
    }
    else if (token.type === ':') {
        const firstComments = s.takeMany('multi-comment').map(helpers_1.createCommentAst);
        const type = s.take(':') || token;
        const isClass = token === type;
        if (isClass) {
            const name = s.take('text');
            const endToken = name || (0, core_1.last)(firstComments) || type;
            ast.push({
                type: 'pseudo_class',
                value: name?.value ?? '',
                start: token.start,
                end: name?.end ?? endToken.end,
                colonComments: firstComments,
            });
        }
        else {
            const secondComments = s.takeMany('multi-comment').map(helpers_1.createCommentAst);
            const name = s.take('text');
            const endToken = name || (0, core_1.last)(secondComments) || type;
            ast.push({
                type: 'pseudo_element',
                value: name?.value ?? '',
                start: token.start,
                end: name?.end ?? endToken.end,
                colonComments: { first: firstComments, second: secondComments },
            });
        }
    }
    else if (token.type === '[') {
        const block = s.run((token, ast) => {
            ast.push(token);
            return token.type !== ']';
        }, [token], source);
        const closed = (0, core_1.last)(block)?.type === ']';
        if (closed) {
            ast.push({
                type: 'attribute',
                value: block.length > 2 ? (0, core_1.getText)(block, 1, block.length - 1, source) : '',
                start: token.start,
                end: (0, core_1.last)(block)?.end ?? token.end,
            });
        }
        else {
            ast.push({
                type: 'invalid',
                value: (0, core_1.getText)(block, undefined, undefined, source),
                start: token.start,
                end: (0, core_1.last)(block)?.end ?? token.end,
            });
        }
    }
    else if ((0, helpers_1.isCombinatorToken)(token)) {
        let lastCombinatorAst = (0, helpers_1.createCombinatorAst)(token);
        let lastAst = lastCombinatorAst;
        // insert token as a combinator
        ast.push(lastCombinatorAst);
        // save the insertion point of the first combinator in case it's a space
        // that might be considered a normal space later and will need to be changed.
        let initialSpaceCombIndex = lastCombinatorAst.combinator === `space` ? ast.length - 1 : -1;
        /**
         * take next spaces/combinators/comments:
         * - combinator/space token:
         *  - spaces: merge to previous ast node before them
         *  - previous ast equal to space combinator
         *    - turn previous ast to the next combinator type
         *    - merge spaces between them
         *    - cancel initial space tracking - must be merged with other non space combinator or already canceled
         *  - initial ast is space (must be comments following it)
         *    - initial space is first in selector: merge initial ast into the selector before
         *    - otherwise merge initial ast the comment following it
         *  - insert an invalid combinator
         * - comment token: insert to ast
         */
        //
        let next = s.next();
        while (next) {
            if ((0, helpers_1.isCombinatorToken)(next)) {
                if (next.type === `space`) {
                    // add space to the last ast node
                    lastAst.after += next.value;
                    lastAst.end = next.end;
                }
                else if (lastAst === lastCombinatorAst && lastAst.combinator === 'space') {
                    // combine next combinator into previous (space)
                    const nextCombinator = (0, helpers_1.createCombinatorAst)(next);
                    lastCombinatorAst.combinator = nextCombinator.combinator;
                    lastCombinatorAst.before +=
                        lastCombinatorAst.after + lastCombinatorAst.value + nextCombinator.before;
                    lastCombinatorAst.after = nextCombinator.after;
                    lastCombinatorAst.value = nextCombinator.value;
                    lastCombinatorAst.end = nextCombinator.end;
                    // reset initial space
                    initialSpaceCombIndex = -1;
                }
                else if (initialSpaceCombIndex !== -1) {
                    // merge initial space combinator (classified as combinator before a comment)
                    const initialSpace = ast[initialSpaceCombIndex];
                    const spaceValue = initialSpace.before + initialSpace.value + initialSpace.after;
                    if (initialSpaceCombIndex === 0) {
                        // merge to beginning of selector
                        currentSelector.before += spaceValue;
                    }
                    else {
                        // merge to the next comment
                        const nodeAfterInitial = ast[initialSpaceCombIndex + 1];
                        if (nodeAfterInitial?.type === `comment`) {
                            nodeAfterInitial.before += spaceValue;
                            nodeAfterInitial.start = initialSpace.start;
                        }
                        else {
                            // shouldn't happen as initial space is considered as a combinator
                            // only when a comment is following it and before
                        }
                    }
                    ast.splice(initialSpaceCombIndex, 1);
                    initialSpaceCombIndex = -1;
                    // add combinator
                    lastCombinatorAst = (0, helpers_1.createCombinatorAst)(next);
                    lastAst = lastCombinatorAst;
                    ast.push(lastCombinatorAst);
                }
                else {
                    // add invalid combinator
                    lastCombinatorAst = (0, helpers_1.createCombinatorAst)(next);
                    lastCombinatorAst.invalid = true;
                    lastAst = lastCombinatorAst;
                    ast.push(lastCombinatorAst);
                }
            }
            else if ((0, core_1.isComment)(next.type)) {
                lastAst = (0, helpers_1.createCommentAst)(next);
                ast.push(lastAst);
            }
            else {
                break;
            }
            next = s.next();
        }
        // put back any unrelated token
        if (next && !(0, helpers_1.isCombinatorToken)(next)) {
            s.back();
        }
    }
    else if (token.type === 'text') {
        ast.push({
            type: 'type',
            value: token.value,
            start: token.start,
            end: token.end,
        });
    }
    else if (token.type === '#') {
        t = s.take('text');
        ast.push({
            type: 'id',
            value: t?.value ?? '',
            start: token.start,
            end: t?.end ?? token.end,
        });
    }
    else if (token.type === '*') {
        ast.push({
            type: 'universal',
            value: '*',
            start: token.start,
            end: token.end,
        });
    }
    else if (token.type === '|') {
        // search backwards compatible namespace in ast
        let prevAst;
        let prevInvalidAst;
        const beforeComments = [];
        for (let i = ast.length - 1; i >= 0; --i) {
            const current = ast[i];
            if ((0, helpers_1.isNamespacedAst)(current)) {
                if (current.namespace) {
                    // already namespaced
                    prevInvalidAst = current;
                }
                else {
                    // merge with previous
                    prevAst = current;
                }
                break;
            }
            else if (current.type === `comment` &&
                current.before === `` &&
                current.after === ``) {
                beforeComments.unshift(current);
            }
            else {
                prevInvalidAst = current;
                break;
            }
        }
        // search forward target token
        let target;
        let searchIndex = 1;
        const potentialAfterComments = [];
        // eslint-disable-next-line no-constant-condition
        while (true) {
            const nextToken = s.peek(searchIndex);
            if ((0, core_1.isComment)(nextToken.type)) {
                potentialAfterComments.push(nextToken);
            }
            else if ((0, helpers_1.isNamespacedToken)(nextToken)) {
                target = nextToken;
                break;
            }
            else {
                // space or end of tokens
                break;
            }
            searchIndex++;
        }
        // create/update ast
        const validNamespace = !prevInvalidAst;
        const validTarget = !!target;
        const type = target?.type === `*` ? `universal` : `type`;
        let invalid = ``;
        // remove before/after pipe comments
        if (validNamespace) {
            ast.splice(ast.length - beforeComments.length, beforeComments.length);
        }
        else {
            invalid = `namespace`;
        }
        if (validTarget) {
            potentialAfterComments.forEach(() => s.next());
            s.next();
        }
        else {
            invalid = invalid ? `namespace,target` : `target`;
        }
        // create new ast or modify the prev
        const nsAst = prevAst ||
            {
                type,
                value: ``,
                start: token.start,
                end: target?.end || token.end,
            };
        nsAst.type = type;
        nsAst.namespace = {
            value: prevAst?.value || ``,
            beforeComments: validNamespace ? beforeComments : [],
            afterComments: validTarget ? potentialAfterComments.map(helpers_1.createCommentAst) : [],
        };
        nsAst.value = target?.value || ``;
        nsAst.end = target?.end || token.end;
        // set invalid
        if (invalid) {
            nsAst.namespace.invalid = invalid;
        }
        // add ast if not modified
        if (!prevAst) {
            ast.push(nsAst);
        }
    }
    else if (token.type === '(') {
        const prev = (0, core_1.last)(ast);
        const res = [];
        // handle nth selector
        if (prev &&
            prev.type === `pseudo_class` &&
            nth_parser_1.NthParser.isNthPseudoClass(prev.value) &&
            s.peek().type !== `)`) {
            // collect "An+B of" expression
            const nthSelector = (0, helpers_1.createEmptyNth)();
            nthSelector.start = s.peek().start;
            res.push(nthSelector);
            const nthParser = new nth_parser_1.NthParser(nthSelector, s);
            s.run((token) => {
                if (nthParser.state === `selector`) {
                    // got to selector, push back and stop
                    s.back();
                    return false;
                }
                return nthParser.handleToken(token);
            }, nthSelector, source);
            // setup next selector
            if (s.peek().type !== `)`) {
                nthSelector.end = (0, core_1.last)(nthSelector.nodes)?.end || nthSelector.start;
                // add "of" selector
                const newSelector = (0, helpers_1.createEmptySelector)();
                newSelector.start = nthSelector.end;
                res.push(newSelector);
            }
        }
        // get all tokens until closed
        s.run((token, selectors) => {
            if (token.type === ')') {
                const currentSelector = (0, core_1.last)(selectors);
                if (currentSelector) {
                    currentSelector.end =
                        (0, core_1.last)(currentSelector.nodes)?.end ?? currentSelector.start;
                }
                return false;
            }
            return handleToken(token, selectors, source, s);
        }, res, source);
        const ended = s.peek(0);
        if (!prev ||
            'nodes' in prev ||
            prev.type === 'invalid' ||
            prev.type === 'combinator' ||
            prev.type === 'comment' ||
            prev.type === 'nth_step' ||
            prev.type === 'nth_dash' ||
            prev.type === 'nth_offset' ||
            prev.type === 'nth_of' ||
            ended.type !== ')') {
            ast.push({
                type: 'invalid',
                value: (0, core_1.getText)([token, ended], undefined, undefined, source),
                start: token.start,
                end: ended?.end ?? s.peekBack().end,
            });
        }
        else {
            const lastSelector = (0, core_1.last)(res);
            if (lastSelector) {
                (0, helpers_1.trimCombinators)(lastSelector);
            }
            prev.nodes = res;
            prev.end = ended.end;
        }
    }
    else if ((0, core_1.isComment)(token.type)) {
        ast.push((0, helpers_1.createCommentAst)(token));
    }
    else if (token.type === ',') {
        // we ensure at least one selector present
        const selector = (0, core_1.last)(selectors);
        selector.end = token.start;
        (0, helpers_1.trimCombinators)(selector);
        const newSelector = (0, helpers_1.createEmptySelector)();
        if (s.done()) {
            newSelector.start = token.end;
            newSelector.end = token.end;
        }
        else {
            newSelector.start = s.peek().start;
        }
        selectors.push(newSelector);
    }
    else if (token.type === '&') {
        ast.push({
            type: 'nesting',
            value: '&',
            start: token.start,
            end: token.end,
        });
    }
    else {
        ast.push({
            type: 'invalid',
            value: token.value,
            start: token.start,
            end: token.end,
        });
    }
    if (s.done()) {
        currentSelector.end = (0, core_1.last)(currentSelector.nodes)?.end ?? currentSelector.start;
        (0, helpers_1.trimCombinators)(currentSelector);
    }
}
//# sourceMappingURL=selector-parser.js.map